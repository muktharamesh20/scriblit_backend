(base) muktharamesh@dhcp-10-29-145-85 scriblit_backend % deno test --allow-read --allow-net --allow-env --allow-sys src/concepts/Scriblink/tags.test.ts
Check file:///Users/muktharamesh/Documents/6104/scriblit_backend/src/concepts/Scriblink/tags.test.ts
running 12 tests from ./src/concepts/Scriblink/tags.test.ts
Principle: User flags items, then retrieves items by tag and tags by item ...
------- output -------

ğŸ·ï¸  OPERATIONAL PRINCIPLE: Tag Management Workflow
============================================================

ğŸ·ï¸  Step 1: Adding tag to item
   âœ… Tag 'important' added to itemA

ğŸ·ï¸  Step 2: Adding same tag to another item
   âœ… Tag 'important' added to itemB (reusing same tag)

ğŸ·ï¸  Step 3: Adding different tag to item
   âœ… Tag 'review' added to itemA (new tag created)

ğŸ” Step 4: Retrieving items by tag
   âœ… Found 2 items with 'important' tag: itemA, itemB

ğŸ” Step 5: Retrieving tags for item
   âœ… Found 2 tags for itemA: 'important', 'review'

ğŸ—‘ï¸  Step 6: Removing tag from item
   âœ… Tag 'important' removed from itemA

ğŸ” Step 7: Verifying tag removal effects
   âœ… 'important' tag now has only itemB (itemA removed)

ğŸ” Step 8: Verifying item's remaining tags
   âœ… itemA now has only 'review' tag

ğŸ” Step 9: Retrieving all user tags
   âœ… User has 2 tags: 'important' (1 item), 'review' (1 item)
   ğŸ“Š Final state: itemA has 'review', itemB has 'important'

ğŸ‰ OPERATIONAL PRINCIPLE COMPLETE
============================================================
----- output end -----
Principle: User flags items, then retrieves items by tag and tags by item ... ok (684ms)
Action: addTag creates new tag or adds to existing, enforces requirements ... ok (618ms)
Action: removeTagFromItem successfully removes association and enforces requirements ... ok (743ms)
Query: _getItemsByTag retrieves associated items or error ... ok (728ms)
Query: _getTagsForItem retrieves tags associated with an item for a specific user ... ok (698ms)
Query: _getTagDetails retrieves full tag structure or error ... ok (630ms)
Query: _getAllUserTags retrieves all tags owned by a user ... ok (700ms)
Interesting Scenario 1: Tag collision and namespace conflicts ...
------- output -------

ğŸ·ï¸  SCENARIO 1: Tag Collision and Namespace Conflicts
1. Testing case-sensitive tag conflicts...
âœ“ All case-sensitive tags accepted as separate tags
2. Testing special character tag conflicts...
âœ“ All special character tags accepted
3. Testing unicode tag conflicts...
âœ“ All unicode tags accepted
4. Testing very long tag names...
âœ“ Very long tag accepted
5. Testing empty and whitespace tags...
âœ“ Empty and whitespace tags correctly rejected

ğŸ‰ SCENARIO 1 COMPLETE
==================================================
----- output end -----
Interesting Scenario 1: Tag collision and namespace conflicts ... ok (1s)
Interesting Scenario 2: Tag semantic similarity and fuzzy matching ...
------- output -------

ğŸ” SCENARIO 2: Tag Semantic Similarity and Fuzzy Matching
1. Creating semantically similar tags...
âœ“ All semantically similar tags created
2. Testing tag retrieval for similar tags...
âœ“ All similar tags retrieved correctly
3. Testing tag variations and typos...
âœ“ All tag variations accepted
4. Testing tag abbreviations and acronyms...
âœ“ All abbreviation tags accepted
5. Testing tags with numbers and versions...
âœ“ All version tags accepted
6. Testing tag removal with similar tags...
âœ“ Urgent tag removed successfully
7. Verifying remaining similar tags...
âœ“ Similar tags preserved after removal
8. Testing tag search with partial matches...
âœ“ Partial tag matching works correctly

ğŸ‰ SCENARIO 2 COMPLETE
==================================================
----- output end -----
Interesting Scenario 2: Tag semantic similarity and fuzzy matching ... ok (2s)
Interesting Scenario 3: Tag performance under high load ...
------- output -------

âš¡ SCENARIO 3: Tag Performance Under High Load
1. Creating tags rapidly...
âœ“ 100 rapid tag creations completed
2. Testing concurrent tag operations...
âœ“ Concurrent operations: 100 succeeded, 0 failed
3. Testing large tag retrieval...
âœ“ Retrieved 100 tags for itemA
4. Performance measurement: 3433ms for all operations
âœ“ Performance within acceptable limits

ğŸ‰ SCENARIO 3 COMPLETE
==================================================
----- output end -----
Interesting Scenario 3: Tag performance under high load ... ok (3s)
Interesting Scenario 4: Tag data corruption and recovery ...
------- output -------

ğŸ”§ SCENARIO 4: Tag Data Corruption and Recovery
1. Creating normal tag structure...
âœ“ Normal tag structure created
2. Testing malformed tag labels...
âœ“ Malformed tag "null-char" accepted (sanitized)
âœ“ Malformed tag "tagwithcontrolchars" accepted (sanitized)
âœ“ Malformed tag "tag
with
newlines" accepted (sanitized)
âœ“ Malformed tag "tag    with    tabs" accepted (sanitized)
3. Testing extremely long tag labels...
âœ“ Extremely long tag accepted
4. Testing duplicate tag handling...
âœ“ Duplicate tag correctly rejected
5. Testing removal of non-existent tag...
âœ“ Non-existent tag removal correctly rejected
6. Verifying data integrity after corruption tests...
âœ“ Data integrity maintained after corruption tests

ğŸ‰ SCENARIO 4 COMPLETE
==================================================
----- output end -----
Interesting Scenario 4: Tag data corruption and recovery ... ok (876ms)
Interesting Scenario 5: Cross-user tag pollution and isolation ...
------- output -------

ğŸ‘¥ SCENARIO 5: Cross-User Tag Pollution and Isolation
1. Alice creating tags...
âœ“ Alice's tags created
2. Bob creating similar tags...
âœ“ Bob's tags created
3. Testing tag isolation between users...
âœ“ Tag isolation maintained between users
4. Testing shared tag concept...
âœ“ Shared tag concept works correctly
5. Verifying Alice's data integrity...
âœ“ Alice's data integrity maintained

ğŸ‰ SCENARIO 5 COMPLETE
==================================================
----- output end -----
Interesting Scenario 5: Cross-user tag pollution and isolation ... ok (767ms)

ok | 12 passed | 0 failed (14s)